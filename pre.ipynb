{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.cluster import MeanShift, DBSCAN\n",
    "\n",
    "# Try importing HDBSCAN (available in scikit-learn >= 1.3)\n",
    "try:\n",
    "    from sklearn.cluster import HDBSCAN\n",
    "    SKLEARN_HDBSCAN = True\n",
    "except ImportError:\n",
    "    SKLEARN_HDBSCAN = False\n",
    "    print(\"WARNING: HDBSCAN not found in sklearn.cluster (requires scikit-learn >= 1.3).\")\n",
    "\n",
    "from typing import Tuple \n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Try importing PyTorch Geometric, handle error gracefully if missing\n",
    "try:\n",
    "    from torch_geometric.nn import DynamicEdgeConv, global_max_pool\n",
    "    PYG_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PYG_AVAILABLE = False\n",
    "    print(\"WARNING: torch_geometric not found. DGCNN will fail to initialize.\")\n",
    "\n",
    "# Try importing Open3D for normal estimation\n",
    "try:\n",
    "    import open3d as o3d\n",
    "    O3D_AVAILABLE = True\n",
    "except ImportError:\n",
    "    O3D_AVAILABLE = False\n",
    "    print(\"WARNING: Open3D not found. Normal estimation will be skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c153f315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device count: 1\n",
      "Device name: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "print(f'Device count: {torch.cuda.device_count()}')\n",
    "print(f'Device name: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "class Config:\n",
    "    \"\"\"Global configuration for training and model parameters.\"\"\"\n",
    "    # Data Params\n",
    "    input_dim = 6  # XYZ (3) + Normals (3). Set to 3 if O3D is missing.\n",
    "    max_points = 2048\n",
    "    \n",
    "    # Model Params\n",
    "    k_neighbors = 20\n",
    "    emb_dim = 128\n",
    "    output_dim = 64\n",
    "    \n",
    "    # Training Params\n",
    "    batch_size = 4\n",
    "    lr = 1e-3\n",
    "    epochs = 50\n",
    "    # First use GPU if available, else if MPS is available (Mac), else CPU\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else \n",
    "                          'mps' if torch.backends.mps.is_available() else \n",
    "                          'cpu')\n",
    "    \n",
    "    # Loss Params (Discriminative Loss)\n",
    "    delta_v = 0.3  # Pull force margin\n",
    "    delta_d = 1.5  # Push force margin\n",
    "    alpha = 1.0    # Weight for pull\n",
    "    beta = 1.0     # Weight for push\n",
    "    gamma = 0.001  # Weight for regularization\n",
    "\n",
    "    # Samopling Params\n",
    "    sampling_method = 'fps'  # 'random' or 'fps' (farthest point sampling)\n",
    "\n",
    "    # clustering methods\n",
    "    clustering_method = 'hdbscan'  # 'mean_shift', 'dbscan', 'hdbscan'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. UTILITIES & PREPROCESSING\n",
    "# ==========================================\n",
    "def compute_normals(points, k=30):\n",
    "    \"\"\"\n",
    "    Computes surface normals using Open3D.\n",
    "    Args:\n",
    "        points: (N, 3) numpy array\n",
    "    Returns:\n",
    "        features: (N, 6) numpy array [x, y, z, nx, ny, nz]\n",
    "    \"\"\"\n",
    "    if not O3D_AVAILABLE:\n",
    "        return points # Return just XYZ if Open3D is missing\n",
    "        \n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    \n",
    "    # Hybrid search for robustness\n",
    "    pcd.estimate_normals(\n",
    "        search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=1.0, max_nn=k)\n",
    "    )\n",
    "    # Consistency check (orient towards Z-axis roughly for roofs)\n",
    "    pcd.orient_normals_towards_camera_location(np.array([0., 0., 100.]))\n",
    "    \n",
    "    normals = np.asarray(pcd.normals)\n",
    "    return np.hstack((points, normals))\n",
    "\n",
    "def normalize_pc(points):\n",
    "    \"\"\"Normalize point cloud to unit sphere at origin.\"\"\"\n",
    "    centroid = np.mean(points[:, :3], axis=0)\n",
    "    points[:, :3] -= centroid\n",
    "    max_dist = np.max(np.sqrt(np.sum(points[:, :3]**2, axis=1)))\n",
    "    points[:, :3] /= max_dist\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. DATASET\n",
    "# ==========================================\n",
    "class LiDARPointCloudDataset(Dataset):\n",
    "    def __init__(self, base_dir, split=\"train\", max_points=2048, sampling_method=\"random\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Root directory containing the 'train_test_split' folder.\n",
    "            split (str): One of 'train', 'val', or 'test'.\n",
    "            max_points (int): Maximum number of points per cloud (for subsampling or padding).\n",
    "            sampling_method (str): 'random' for random subsampling, 'fps' for Farthest Point Sampling.\n",
    "        \"\"\"\n",
    "        self.base_dir = base_dir\n",
    "        self.split = split\n",
    "        self.max_points = max_points\n",
    "        self.sampling_method = sampling_method\n",
    "        \n",
    "        # Determine internal mode: 'train' enables relabeling, others strictly eval\n",
    "        self.mode = \"train\" if split == \"train\" else \"eval\"\n",
    "\n",
    "        # Construct paths based on the requested structure:\n",
    "        # data/train_test_split/points_{split}_n\n",
    "        # base_dir = os.path.join(root_dir, \"train_test_split\")\n",
    "        self.point_folder = os.path.join(base_dir, f\"points_{split}_n\")\n",
    "        self.label_folder = os.path.join(base_dir, f\"labels_{split}_n\")\n",
    "\n",
    "        # Ensure directories exist (or handle gracefully)\n",
    "        if not os.path.exists(self.point_folder) or not os.path.exists(self.label_folder):\n",
    "            print(f\"WARNING: Data folders not found for split '{split}':\\n  {self.point_folder}\\n  {self.label_folder}\")\n",
    "            self.point_files = []\n",
    "            self.label_files = []\n",
    "        else:\n",
    "            # List all available point files\n",
    "            self.point_files = sorted([f for f in os.listdir(self.point_folder) if f.endswith(\".txt\")])\n",
    "            self.label_files = sorted([f for f in os.listdir(self.label_folder) if f.endswith(\".txt\")])\n",
    "\n",
    "            # Ensure matching point and label files\n",
    "            assert len(self.point_files) == len(self.label_files), \\\n",
    "                f\"Mismatch in points and labels count for split '{split}'.\"\n",
    "\n",
    "    def _farthest_point_sampling(self, points, n_samples):\n",
    "        \"\"\"\n",
    "        Performs Farthest Point Sampling (FPS).\n",
    "        Selects points that are farthest from each other to ensure uniform coverage.\n",
    "        \n",
    "        Args:\n",
    "            points: (N, 3) or (N, D) numpy array\n",
    "            n_samples: int, number of points to select\n",
    "        Returns:\n",
    "            indices: (n_samples,) numpy array of selected indices\n",
    "        \"\"\"\n",
    "        N, D = points.shape\n",
    "        xyz = points[:, :3]  # Use only spatial coordinates for distance\n",
    "        centroids = np.zeros((n_samples,), dtype=np.int64)\n",
    "        \n",
    "        # Initialize distances with infinity\n",
    "        distance = np.ones((N,), dtype=np.float64) * 1e10\n",
    "        \n",
    "        # Select the first point randomly\n",
    "        farthest = np.random.randint(0, N)\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            centroids[i] = farthest\n",
    "            centroid = xyz[farthest, :]\n",
    "            \n",
    "            # Calculate Euclidean distance from the current centroid to all points\n",
    "            dist = np.sum((xyz - centroid) ** 2, axis=1)\n",
    "            \n",
    "            # Update the minimum distance to any selected point for all points\n",
    "            mask = dist < distance\n",
    "            distance[mask] = dist[mask]\n",
    "            \n",
    "            # Select the point with the maximum distance to the set of selected points\n",
    "            farthest = np.argmax(distance)\n",
    "            \n",
    "        return centroids\n",
    "\n",
    "    def load_txt_file(self, file_path, num_features=3):\n",
    "        \"\"\"\n",
    "        Loads a .txt file, converting string lines into a NumPy array of type float64.\n",
    "        Assumes space/comma-separated values.\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        with open(file_path, \"r\") as file:\n",
    "            for line in file:\n",
    "                try:\n",
    "                    values = np.array(line.strip().replace(',', ' ').split(), dtype=np.float64)\n",
    "                    if len(values) == num_features:\n",
    "                        data.append(values)\n",
    "                except ValueError:\n",
    "                    continue  # Skip lines that cannot be converted\n",
    "        \n",
    "        if len(data) == 0:\n",
    "            return np.zeros((0, num_features), dtype=np.float64)\n",
    "\n",
    "        return np.array(data)\n",
    "\n",
    "    def load_point_cloud(self, file_path):\n",
    "        \"\"\"Loads point cloud (XYZ) from a .txt file and returns a NumPy array.\"\"\"\n",
    "        return self.load_txt_file(file_path, num_features=3)  # Expecting [x, y, z]\n",
    "\n",
    "    def load_labels(self, file_path, num_points):\n",
    "        \"\"\"Loads labels from a .txt file, ensuring it matches the number of points.\"\"\"\n",
    "        labels = self.load_txt_file(file_path, num_features=1).flatten()\n",
    "        if len(labels) != num_points:\n",
    "            print(f\"Warning: {file_path} has {len(labels)} labels, expected {num_points}. Using zero-padding.\")\n",
    "            labels = np.pad(labels, (0, max(0, num_points - len(labels))), 'constant', constant_values=0)\n",
    "        return labels\n",
    "\n",
    "    def relabel_instances(self, labels):\n",
    "        \"\"\"\n",
    "        Relabels instance IDs to be 0-indexed and returns the new labels + instance count.\n",
    "        Padding labels (-1) are ignored.\n",
    "        \"\"\"\n",
    "        valid_mask = labels != -1\n",
    "        unique = np.unique(labels[valid_mask])\n",
    "\n",
    "        if len(unique) == 0:\n",
    "            # No valid instances: return all -1s and count = 0\n",
    "            return np.full_like(labels, -1, dtype=np.int64), 0\n",
    "\n",
    "        remap = {old: new for new, old in enumerate(unique)}\n",
    "        relabeled = np.array([remap.get(l, -1) for l in labels], dtype=np.int64)\n",
    "        return relabeled, len(unique)\n",
    "\n",
    "    def pad_or_subsample(self, points, labels):\n",
    "        \"\"\"Ensures a fixed number of points per cloud using padding or subsampling.\"\"\"\n",
    "        num_points = points.shape[0]\n",
    "\n",
    "        if num_points > self.max_points:\n",
    "            # Downsample\n",
    "            if self.sampling_method == 'fps':\n",
    "                indices = self._farthest_point_sampling(points, self.max_points)\n",
    "            else:\n",
    "                # Randomly sample points\n",
    "                indices = np.random.choice(num_points, self.max_points, replace=False)\n",
    "            \n",
    "            points, labels = points[indices], labels[indices]\n",
    "            \n",
    "        elif num_points < self.max_points:\n",
    "            # Pad with zeros\n",
    "            pad_size = self.max_points - num_points\n",
    "            pad_points = np.zeros((pad_size, 3), dtype=np.float64)\n",
    "            pad_labels = np.full(pad_size, -1, dtype=np.int64)\n",
    "            points = np.vstack((points, pad_points))\n",
    "            labels = np.hstack((labels, pad_labels))\n",
    "\n",
    "        return points, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.point_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        point_path = os.path.join(self.point_folder, self.point_files[idx])\n",
    "        label_path = os.path.join(self.label_folder, self.label_files[idx])\n",
    "\n",
    "        point_cloud = self.load_point_cloud(point_path)\n",
    "        labels = self.load_labels(label_path, num_points=point_cloud.shape[0])\n",
    "\n",
    "        # Apply padding or subsampling\n",
    "        point_cloud, labels = self.pad_or_subsample(point_cloud, labels)\n",
    "        \n",
    "        # --- METHODOLOGICAL INTEGRATION (Normals + Normalization) ---\n",
    "        # 1. Compute Normals if configured (Enhancement #1)\n",
    "        if Config.input_dim == 6:\n",
    "            # Note: compute_normals expects (N, 3) and returns (N, 6)\n",
    "            point_cloud = compute_normals(point_cloud)\n",
    "\n",
    "        # 2. Normalize XYZ (Essential for stability)\n",
    "        point_cloud = normalize_pc(point_cloud)\n",
    "        # ------------------------------------------------------------\n",
    "\n",
    "        # Relabel + get instance count (done last to handle padded -1s correctly)\n",
    "        if self.mode == \"train\":\n",
    "            labels, instance_count = self.relabel_instances(labels)\n",
    "        else:\n",
    "            instance_count = len(np.unique(labels[labels != -1]))\n",
    "\n",
    "        return torch.tensor(point_cloud, dtype=torch.float32), torch.tensor(labels, dtype=torch.long), instance_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4. MODEL ARCHITECTURE (DGCNN + UNet)\n",
    "# ==========================================\n",
    "class DGCNNEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Innovative Encoder using Dynamic Graph CNN (Wang et al., 2019).\n",
    "    dynamically computes graphs in feature space to capture local geometric structure.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=6, k=20, emb_dim=128):\n",
    "        super(DGCNNEncoder, self).__init__()\n",
    "        if not PYG_AVAILABLE:\n",
    "            raise ImportError(\"PyTorch Geometric required for DGCNN.\")\n",
    "            \n",
    "        self.k = k\n",
    "        \n",
    "        # EdgeConv 1\n",
    "        self.conv1 = DynamicEdgeConv(\n",
    "            nn=nn.Sequential(nn.Linear(input_dim * 2, 64), nn.BatchNorm1d(64), nn.LeakyReLU(0.2)), k=k)\n",
    "        # EdgeConv 2\n",
    "        self.conv2 = DynamicEdgeConv(\n",
    "            nn=nn.Sequential(nn.Linear(64 * 2, 64), nn.BatchNorm1d(64), nn.LeakyReLU(0.2)), k=k)\n",
    "        # EdgeConv 3\n",
    "        self.conv3 = DynamicEdgeConv(\n",
    "            nn=nn.Sequential(nn.Linear(64 * 2, 128), nn.BatchNorm1d(128), nn.LeakyReLU(0.2)), k=k)\n",
    "        \n",
    "        # Final projection\n",
    "        self.lin_block = nn.Sequential(\n",
    "            nn.Linear(128, emb_dim), nn.BatchNorm1d(emb_dim), nn.LeakyReLU(0.2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape input: (Batch, Channels, Points)\n",
    "        B, C, N = x.shape\n",
    "        \n",
    "        # Reshape for PyG: (Total_Points, Channels)\n",
    "        x_flat = x.permute(0, 2, 1).contiguous().view(B * N, C)\n",
    "        batch_idx = torch.arange(B, device=x.device).repeat_interleave(N)\n",
    "\n",
    "        # Dynamic Edge Convolutions\n",
    "        x1 = self.conv1(x_flat, batch_idx)\n",
    "        x2 = self.conv2(x1, batch_idx)\n",
    "        x3 = self.conv3(x2, batch_idx)\n",
    "        \n",
    "        # Local features\n",
    "        local_feat = self.lin_block(x3) # (Total_Points, emb_dim)\n",
    "        \n",
    "        # Global Max Pool\n",
    "        global_feat = global_max_pool(local_feat, batch_idx) # (B, emb_dim)\n",
    "        \n",
    "        # Reshape back to standard tensor format\n",
    "        # Local: (B, N, emb_dim) -> (B, emb_dim, N)\n",
    "        local_feat = local_feat.view(B, N, -1).permute(0, 2, 1)\n",
    "        \n",
    "        # Expand global to match local\n",
    "        global_feat_expanded = global_feat.unsqueeze(-1).repeat(1, 1, N)\n",
    "        \n",
    "        # Concatenate for Skip Connection capability\n",
    "        # Returns: (B, 2*emb_dim, N)\n",
    "        return torch.cat([local_feat, global_feat_expanded], dim=1)\n",
    "\n",
    "\n",
    "class SipUNetDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decodes the global+local features back to per-point embeddings.\n",
    "    Standard 1D Convolutional Decoder.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels, output_dim=64):\n",
    "        super(SipUNetDecoder, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 128, 1)\n",
    "        self.conv2 = nn.Conv1d(128, 64, 1)\n",
    "        self.conv3 = nn.Conv1d(64, output_dim, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.bn3 = nn.BatchNorm1d(output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x)) # No Activation on final layer (embedding space)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PointUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Main Model Wrapper.\n",
    "    Encoder: DGCNN (Context Aware)\n",
    "    Decoder: Simple Conv (Pointwise)\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(PointUNet, self).__init__()\n",
    "        self.encoder = DGCNNEncoder(input_dim=config.input_dim, k=config.k_neighbors, emb_dim=config.emb_dim)\n",
    "        # Encoder outputs 2*emb_dim (local + global)\n",
    "        self.decoder = SipUNetDecoder(input_channels=config.emb_dim * 2, output_dim=config.output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, N, C) -> Permute to (B, C, N)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        features = self.encoder(x) # (B, 2*emb, N)\n",
    "        embeddings = self.decoder(features) # (B, out_dim, N)\n",
    "        return embeddings.permute(0, 2, 1) # Return (B, N, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 5. DISCRIMINATIVE LOSS\n",
    "# ==========================================\n",
    "class DiscriminativeLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Discriminative loss for instance segmentation in embedding space.\n",
    "    (De Brabandere et al. 2017)\n",
    "    \n",
    "    Encourages:\n",
    "        - points of the same instance to be close to their cluster center (delta_v)\n",
    "        - instance centers to be far apart (delta_d)\n",
    "        - small norm of cluster centers (regularizer)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        delta_v: float = 0.3, \n",
    "        delta_d: float = 1.5, \n",
    "        alpha: float = 1.0, \n",
    "        beta: float = 1.0, \n",
    "        gamma: float = 0.001,\n",
    "        ignore_label: int = -1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.delta_v = delta_v\n",
    "        self.delta_d = delta_d\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.ignore_label = ignore_label\n",
    "\n",
    "    def forward(self, embeddings, instance_labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embeddings: (B, N, D)\n",
    "            instance_labels: (B, N)\n",
    "        \"\"\"\n",
    "        batch_size = embeddings.shape[0]\n",
    "        total_loss = 0.0\n",
    "        valid_batches = 0\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            emb = embeddings[b] # (N, D)\n",
    "            lbl = instance_labels[b] # (N,)\n",
    "            \n",
    "            # Filter ignore label\n",
    "            mask = lbl != self.ignore_label\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "\n",
    "            emb_valid = emb[mask]\n",
    "            lbl_valid = lbl[mask]\n",
    "            \n",
    "            unique_labels = torch.unique(lbl_valid)\n",
    "            num_instances = len(unique_labels)\n",
    "            \n",
    "            if num_instances == 0:\n",
    "                continue\n",
    "\n",
    "            # Compute cluster centers\n",
    "            mu_list = []\n",
    "            for inst_id in unique_labels:\n",
    "                inst_mask = (lbl_valid == inst_id)\n",
    "                mu_list.append(emb_valid[inst_mask].mean(dim=0))\n",
    "            \n",
    "            mu_tensor = torch.stack(mu_list) # (K, D)\n",
    "\n",
    "            # --- 1. Variance Term (Pull) ---\n",
    "            l_var = 0.0\n",
    "            for i, inst_id in enumerate(unique_labels):\n",
    "                inst_mask = (lbl_valid == inst_id)\n",
    "                inst_emb = emb_valid[inst_mask]\n",
    "                center = mu_tensor[i].unsqueeze(0) # (1, D)\n",
    "                \n",
    "                # Distance of points to their own center\n",
    "                dist = torch.norm(inst_emb - center, dim=1)\n",
    "                \n",
    "                # Hinge: max(0, dist - delta_v)^2\n",
    "                hinge = torch.clamp(dist - self.delta_v, min=0) ** 2\n",
    "                l_var += hinge.mean()\n",
    "            \n",
    "            l_var /= num_instances\n",
    "            \n",
    "            # --- 2. Distance Term (Push) ---\n",
    "            l_dist = 0.0\n",
    "            if num_instances > 1:\n",
    "                # Optimized: Use cdist instead of nested loops for performance\n",
    "                # Using p=1 (Manhattan) to match provided snippet integration request\n",
    "                dist_mat = torch.cdist(mu_tensor, mu_tensor, p=1)\n",
    "                \n",
    "                # Create mask to ignore diagonal (dist to self is 0)\n",
    "                diag_mask = torch.eye(num_instances, device=embeddings.device).bool()\n",
    "                \n",
    "                # Hinge: max(0, 2*delta_d - dist)^2\n",
    "                dist_hinge = torch.clamp(2 * self.delta_d - dist_mat, min=0) ** 2\n",
    "                \n",
    "                # Zero out diagonals\n",
    "                dist_hinge[diag_mask] = 0.0\n",
    "                \n",
    "                l_dist = dist_hinge.sum() / (num_instances * (num_instances - 1))\n",
    "            \n",
    "            # --- 3. Regularization Term ---\n",
    "            # Using p=1 (L1 norm) for regularization as per snippet\n",
    "            l_reg = torch.norm(mu_tensor, p=1, dim=1).mean()\n",
    "\n",
    "            # Combine\n",
    "            total_loss += self.alpha * l_var + self.beta * l_dist + self.gamma * l_reg\n",
    "            valid_batches += 1\n",
    "\n",
    "        if valid_batches == 0:\n",
    "            return torch.tensor(0.0, device=embeddings.device, requires_grad=True)\n",
    "\n",
    "        return total_loss / valid_batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 6. CLUSTERING (INFERENCE)\n",
    "# ==========================================\n",
    "def cluster_embeddings(embeddings, method='meanshift'):\n",
    "    \"\"\"\n",
    "    Post-processing: Turns embeddings into instance labels.\n",
    "    Args:\n",
    "        embeddings: (N, D) numpy array\n",
    "        method: 'meanshift' or 'hdbscan' or 'dbscan'\n",
    "    Returns:\n",
    "        labels: (N,) numpy array\n",
    "    \"\"\"\n",
    "    if method == 'meanshift':\n",
    "        # Bandwidth is the crucial hyperparam here\n",
    "        # Can be estimated via sklearn.cluster.estimate_bandwidth\n",
    "        ms = MeanShift(bandwidth=0.6, bin_seeding=True)\n",
    "        labels = ms.fit_predict(embeddings)\n",
    "        \n",
    "    elif method == 'dbscan':\n",
    "        # More robust, faster than MeanShift for large N\n",
    "        db = DBSCAN(eps=0.5, min_samples=10)\n",
    "        labels = db.fit_predict(embeddings)\n",
    "        \n",
    "    elif method == 'hdbscan':\n",
    "        if SKLEARN_HDBSCAN:\n",
    "            # Robust to variable densities, no 'epsilon' parameter needed\n",
    "            # min_cluster_size: Smallest valid roof face size\n",
    "            # min_samples: Measure of 'conservativeness' (larger = more points marked as noise)\n",
    "            clusterer = HDBSCAN(min_cluster_size=15, min_samples=5, cluster_selection_method='eom')\n",
    "            labels = clusterer.fit_predict(embeddings)\n",
    "        else:\n",
    "            print(\"HDBSCAN requested but not installed. Falling back to DBSCAN.\")\n",
    "            db = DBSCAN(eps=0.5, min_samples=10)\n",
    "            labels = db.fit_predict(embeddings)\n",
    "        \n",
    "    # TODO: Implement RANSAC plane fitting refinement here for production\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 7. MAIN EXECUTION\n",
    "# ==========================================\n",
    "def train_pipeline(conf: Config = None, data_root=\"data/roofNTNU/train_test_split\", json_log_path=\"training_log.json\", save_model_path=\"roof_segmentation_dgcnn_best.pth\"):\n",
    "    # 1. Setup\n",
    "    if conf is None:\n",
    "        conf = Config()\n",
    "    \n",
    "    if not PYG_AVAILABLE:\n",
    "        print(\"Cannot run without PyG. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Initializing Model: DGCNN -> PointUNet on {conf.device}\")\n",
    "    model = PointUNet(conf).to(conf.device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=conf.lr)\n",
    "    \n",
    "    # Initialize Loss Module\n",
    "    criterion = DiscriminativeLoss(\n",
    "        delta_v=conf.delta_v,\n",
    "        delta_d=conf.delta_d,\n",
    "        alpha=conf.alpha,\n",
    "        beta=conf.beta,\n",
    "        gamma=conf.gamma\n",
    "    ).to(conf.device)\n",
    "    \n",
    "    # Prepare Logging\n",
    "    # We serialize the config class attributes to a dict\n",
    "    log_data = {\n",
    "        \"config\": {k: str(v) for k, v in Config.__dict__.items() if not k.startswith('__')},\n",
    "        \"history\": []\n",
    "    }\n",
    "    \n",
    "    # 2. Data\n",
    "    # root_dir should contain the 'train_test_split' folder\n",
    "    # data_root = \"data/roofNTNU/train_test_split\" \n",
    "    \n",
    "    # Initialize datasets for Train and Validation splits\n",
    "    train_dataset = LiDARPointCloudDataset(\n",
    "        base_dir=data_root, \n",
    "        split='train', \n",
    "        max_points=conf.max_points,\n",
    "        sampling_method=conf.sampling_method\n",
    "    )\n",
    "    \n",
    "    val_dataset = LiDARPointCloudDataset(\n",
    "        base_dir=data_root, \n",
    "        split='val', \n",
    "        max_points=conf.max_points,\n",
    "        sampling_method=conf.sampling_method\n",
    "    )\n",
    "    \n",
    "    # Check if data exists\n",
    "    if len(train_dataset) == 0:\n",
    "        print(f\"No training files found in '{data_root}/'. Exiting.\")\n",
    "        # return # Commented out for dry-run/template purposes\n",
    "\n",
    "    # Dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=conf.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=conf.batch_size, shuffle=False)\n",
    "    \n",
    "    # 3. Training Loop\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(conf.epochs):\n",
    "        # --- TRAINING ---\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{conf.epochs} [Train]\")\n",
    "        \n",
    "        for points, labels, _ in loop:\n",
    "            points = points.to(conf.device)\n",
    "            labels = labels.to(conf.device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            embeddings = model(points)\n",
    "            loss = criterion(embeddings, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "            \n",
    "        avg_train_loss = train_loss / len(train_loader) if len(train_loader) > 0 else 0\n",
    "        \n",
    "        # --- VALIDATION ---\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        if len(val_loader) > 0:\n",
    "            with torch.no_grad():\n",
    "                for points, labels, _ in val_loader:\n",
    "                    points = points.to(conf.device)\n",
    "                    labels = labels.to(conf.device)\n",
    "                    \n",
    "                    embeddings = model(points)\n",
    "                    loss = criterion(embeddings, labels)\n",
    "                    val_loss += loss.item()\n",
    "            \n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n",
    "            \n",
    "            # Save Best Model\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), \"roof_segmentation_dgcnn_best.pth\")\n",
    "                print(\"  -> New best model saved.\")\n",
    "        else:\n",
    "            avg_val_loss = None\n",
    "            print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f} (No Validation Data)\")\n",
    "        \n",
    "        # --- LOGGING ---\n",
    "        epoch_stats = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": avg_train_loss,\n",
    "            \"val_loss\": avg_val_loss\n",
    "        }\n",
    "        log_data[\"history\"].append(epoch_stats)\n",
    "        \n",
    "        # Save log to JSON file (overwriting each epoch to keep it current)\n",
    "        with open(json_log_path, \"w\") as f:\n",
    "            json.dump(log_data, f, indent=4)\n",
    "        \n",
    "        # 4. Quick Inference Check (On Validation Sample)\n",
    "        if epoch % 10 == 0 and len(val_dataset) > 0:\n",
    "            with torch.no_grad():\n",
    "                # Grab a sample from validation set\n",
    "                points_sample, _, _ = val_dataset[0]\n",
    "                points_sample = points_sample.unsqueeze(0).to(conf.device)\n",
    "                \n",
    "                sample_emb = model(points_sample)[0].cpu().numpy() # (N, D)\n",
    "                pred_labels = cluster_embeddings(sample_emb, method='hdbscan')\n",
    "                print(f\"  [Inference Check] Found {len(np.unique(pred_labels))} instances in a validation sample.\")\n",
    "\n",
    "    # Save final model\n",
    "    torch.save(model.state_dict(), save_model_path)\n",
    "    print(\"Training Complete. Log saved to training_log.json.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Model: DGCNN -> PointUNet on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [Train]:   7%|â–‹         | 13/197 [00:08<01:55,  1.60it/s, loss=4.46]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m     log_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_log.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroof_segmentation_dgcnn_best.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mtrain_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/roofNTNU/train_test_split\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_log_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# ==========================================\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# End of Script\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 71\u001b[0m, in \u001b[0;36mtrain_pipeline\u001b[0;34m(conf, data_root, json_log_path, save_model_path)\u001b[0m\n\u001b[1;32m     67\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     69\u001b[0m loop \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconf\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [Train]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m points, labels, _ \u001b[38;5;129;01min\u001b[39;00m loop:\n\u001b[1;32m     72\u001b[0m     points \u001b[38;5;241m=\u001b[39m points\u001b[38;5;241m.\u001b[39mto(conf\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     73\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(conf\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/LiDARML/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/LiDARML/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/LiDARML/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/LiDARML/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/LiDARML/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[8], line 161\u001b[0m, in \u001b[0;36mLiDARPointCloudDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    158\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_labels(label_path, num_points\u001b[38;5;241m=\u001b[39mpoint_cloud\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# Apply padding or subsampling\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m point_cloud, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_or_subsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint_cloud\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# --- METHODOLOGICAL INTEGRATION (Normals + Normalization) ---\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# 1. Compute Normals if configured (Enhancement #1)\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Config\u001b[38;5;241m.\u001b[39minput_dim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m6\u001b[39m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# Note: compute_normals expects (N, 3) and returns (N, 6)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 133\u001b[0m, in \u001b[0;36mLiDARPointCloudDataset.pad_or_subsample\u001b[0;34m(self, points, labels)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_points \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_points:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# Downsample\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfps\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 133\u001b[0m         indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_farthest_point_sampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_points\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;66;03m# Randomly sample points\u001b[39;00m\n\u001b[1;32m    136\u001b[0m         indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(num_points, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_points, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[8], line 67\u001b[0m, in \u001b[0;36mLiDARPointCloudDataset._farthest_point_sampling\u001b[0;34m(self, points, n_samples)\u001b[0m\n\u001b[1;32m     64\u001b[0m centroid \u001b[38;5;241m=\u001b[39m xyz[farthest, :]\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Calculate Euclidean distance from the current centroid to all points\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxyz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcentroid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Update the minimum distance to any selected point for all points\u001b[39;00m\n\u001b[1;32m     70\u001b[0m mask \u001b[38;5;241m=\u001b[39m dist \u001b[38;5;241m<\u001b[39m distance\n",
      "File \u001b[0;32m~/miniconda3/envs/LiDARML/lib/python3.10/site-packages/numpy/_core/fromnumeric.py:2466\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2463\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2467\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\n\u001b[1;32m   2469\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/LiDARML/lib/python3.10/site-packages/numpy/_core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    conf = Config()\n",
    "    if not os.path.exists(\"logs\"):\n",
    "        os.makedirs(\"logs\")\n",
    "    if not os.path.exists(\"models\"):\n",
    "        os.makedirs(\"models\")\n",
    "    log_path = os.path.join(\"logs\", \"training_log.json\")\n",
    "    model_path = os.path.join(\"models\", \"roof_segmentation_dgcnn_best.pth\")\n",
    "    train_pipeline(conf, data_root=\"data/roofNTNU/train_test_split\", json_log_path=log_path, save_model_path=model_path)\n",
    "# ==========================================\n",
    "# End of Script\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LiDARML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
