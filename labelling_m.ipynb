{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Point Cloud ⇢ Wireframe Face Labeller (faces-from-lines with coplanar merge)\n",
    "\n",
    "Goal: avoid the common over-segmentation where one intended face is recognized\n",
    "as two (or more) due to diagonals/chords in the wireframe. This script:\n",
    "\n",
    "1) Parses OBJ (v + l).\n",
    "2) Detects simple cycles (3+ edges) that are approximately coplanar.\n",
    "3) Groups cycles by plane (normal & offset tolerance).\n",
    "4) **Merges coplanar, overlapping cycles into single faces** (prefers Shapely\n",
    "   polygon union; falls back to a chord-pruning heuristic if Shapely isn't\n",
    "   available).\n",
    "5) Assigns each XYZ point to the merged faces and writes XYZ-only + FACE_ID.\n",
    "\n",
    "Output format: each row → X Y Z FACE_ID (−1 if no match).\n",
    "\n",
    "Dependencies:\n",
    "- numpy, scipy (KDTree). Optional: shapely (strongly recommended for robust\n",
    "  merge of coplanar loops with holes).\n",
    "\n",
    "Usage\n",
    "-----\n",
    "python pointcloud_label_by_wireframe_merged.py \\\n",
    "  --xyz input.xyz \\\n",
    "  --obj frame.obj \\\n",
    "  --out labelled.xyz \\\n",
    "  --plane_tol 0.02 \\\n",
    "  --ang_tol_deg 2.0 \\\n",
    "  --plane_d_tol 0.05 \\\n",
    "  --max_distance 2.0 \\\n",
    "  --cycle_len_max 32 \\\n",
    "  --chunk_size 200000\n",
    "\n",
    "Tolerances (CRS units, e.g., meters):\n",
    "* plane_tol: RMS distance of loop vertices to its best-fit plane.\n",
    "* ang_tol_deg: angle threshold for plane normal similarity when grouping.\n",
    "* plane_d_tol: allowed plane offset difference when grouping faces by plane.\n",
    "* max_distance: max perpendicular distance of a point from plane to be inside.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "import argparse, math, sys\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Iterable, Optional\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "try:\n",
    "    from shapely.geometry import Polygon\n",
    "    from shapely.ops import unary_union\n",
    "    _HAVE_SHAPELY = True\n",
    "except Exception:\n",
    "    _HAVE_SHAPELY = False\n",
    "\n",
    "display(f\"Shapely available: {_HAVE_SHAPELY}\")\n",
    "\n",
    "# ---------------------------- OBJ parsing ---------------------------------- #\n",
    "\n",
    "def parse_obj(path: Path):\n",
    "    verts, lines = [], []\n",
    "    with path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for raw in f:\n",
    "            s = raw.strip()\n",
    "            if not s or s.startswith(\"#\"): continue\n",
    "            if s.startswith(\"v \"):\n",
    "                _, xs, ys, zs, *rest = s.split()\n",
    "                verts.append([float(xs), float(ys), float(zs)])\n",
    "            elif s.startswith(\"l \"):\n",
    "                parts = s.split()[1:]\n",
    "                vids = [int(p.split(\"/\")[0]) - 1 for p in parts]\n",
    "                for a, b in zip(vids, vids[1:]):\n",
    "                    if a != b:\n",
    "                        lines.append((min(a, b), max(a, b)))\n",
    "    return np.asarray(verts, float), sorted(set(lines))\n",
    "\n",
    "# ----------------------------- Geometry ------------------------------------ #\n",
    "\n",
    "def fit_plane(points: np.ndarray):\n",
    "    c = points.mean(0)\n",
    "    Q = points - c\n",
    "    _, _, VT = np.linalg.svd(Q, full_matrices=False)\n",
    "    n = VT[-1]\n",
    "    n = n / (np.linalg.norm(n) + 1e-12)\n",
    "    rms = float(np.sqrt(np.mean((Q @ n) ** 2)))\n",
    "    return c, n, rms\n",
    "\n",
    "def plane_basis(n: np.ndarray):\n",
    "    n = n / (np.linalg.norm(n) + 1e-12)\n",
    "    a = np.array([1.0, 0.0, 0.0])\n",
    "    if abs(np.dot(a, n)) > 0.9:\n",
    "        a = np.array([0.0, 1.0, 0.0])\n",
    "    u = np.cross(n, a); u /= (np.linalg.norm(u) + 1e-12)\n",
    "    v = np.cross(n, u); v /= (np.linalg.norm(v) + 1e-12)\n",
    "    return u, v\n",
    "\n",
    "def project_points(P: np.ndarray, origin: np.ndarray, n: np.ndarray) -> np.ndarray:\n",
    "    u, v = plane_basis(n)\n",
    "    Q = P - origin\n",
    "    return np.stack([Q @ u, Q @ v], axis=1)\n",
    "\n",
    "# ----------------------------- Cycles -------------------------------------- #\n",
    "\n",
    "def build_adj(nv: int, lines: List[Tuple[int,int]]):\n",
    "    adj = [[] for _ in range(nv)]\n",
    "    for a,b in lines:\n",
    "        adj[a].append(b); adj[b].append(a)\n",
    "    for lst in adj: lst.sort()\n",
    "    return adj\n",
    "\n",
    "def find_simple_cycles(adj, maxlen=32):\n",
    "    n = len(adj)\n",
    "    cycles, seen = [], set()\n",
    "    def canonical(path):\n",
    "        m = min(path); i = path.index(m)\n",
    "        rot = path[i:] + path[:i]\n",
    "        r1, r2 = tuple(rot), tuple(reversed(rot))\n",
    "        return r1 if r1 < r2 else r2\n",
    "    def dfs(start,u,parent,stack,blocked):\n",
    "        if len(stack) > maxlen: return\n",
    "        for v in adj[u]:\n",
    "            if v == parent: continue\n",
    "            if v == start and len(stack) >= 3:\n",
    "                key = canonical(stack)\n",
    "                if key not in seen:\n",
    "                    seen.add(key); cycles.append(list(key))\n",
    "                continue\n",
    "            if v in blocked or v in stack: continue\n",
    "            stack.append(v); dfs(start,v,u,stack,blocked); stack.pop()\n",
    "    blocked=set()\n",
    "    for s in range(n):\n",
    "        if not adj[s]: continue\n",
    "        dfs(s,s,-1,[s],blocked); blocked.add(s)\n",
    "    return cycles\n",
    "\n",
    "# -------------- Build faces from lines & merge coplanar -------------------- #\n",
    "\n",
    "def derive_cycles_as_faces(V, lines, plane_tol: float, cycle_len_max: int):\n",
    "    \"\"\"Return list of provisional faces dicts: origin, normal, poly2d, vids.\"\"\"\n",
    "    adj = build_adj(len(V), lines)\n",
    "    faces = []\n",
    "    for cyc in find_simple_cycles(adj, cycle_len_max):\n",
    "        pts = V[np.array(cyc)]\n",
    "        origin, normal, rms = fit_plane(pts)\n",
    "        if rms > plane_tol:\n",
    "            continue\n",
    "        poly2d = project_points(pts, origin, normal)\n",
    "        # discard degenerate\n",
    "        area = 0.5 * float(np.dot(poly2d[:,0], np.roll(poly2d[:,1], -1)) - np.dot(poly2d[:,1], np.roll(poly2d[:,0], -1)))\n",
    "        if abs(area) < 1e-12:\n",
    "            continue\n",
    "        faces.append({'vertex_ids':cyc,'origin':origin,'normal':normal,'poly2d':poly2d})\n",
    "    return faces\n",
    "\n",
    "def group_by_plane(faces: List[Dict], ang_tol_deg: float, plane_d_tol: float):\n",
    "    groups: List[List[int]] = []\n",
    "    used = [False]*len(faces)\n",
    "    ang_tol = math.radians(ang_tol_deg)\n",
    "    for i, f in enumerate(faces):\n",
    "        if used[i]: continue\n",
    "        used[i] = True\n",
    "        group = [i]\n",
    "        n0 = f['normal']; o0 = f['origin']\n",
    "        for j in range(i+1, len(faces)):\n",
    "            if used[j]:\n",
    "                continue\n",
    "            nj = faces[j]['normal']; oj = faces[j]['origin']\n",
    "            # orientation-insensitive\n",
    "            cosang = abs(np.clip(np.dot(n0, nj), -1.0, 1.0))\n",
    "            if cosang < math.cos(ang_tol):\n",
    "                continue\n",
    "            # plane offset distance along normal\n",
    "            d = abs(np.dot(oj - o0, n0))\n",
    "            if d <= plane_d_tol:\n",
    "                used[j] = True\n",
    "                group.append(j)\n",
    "        groups.append(group)\n",
    "    return groups\n",
    "\n",
    "# --------------------------- Merge with Shapely ---------------------------- #\n",
    "\n",
    "def merge_group_shapely(V, faces: List[Dict], idxs: List[int]):\n",
    "    \"\"\"Return list of merged faces (with holes handled) using Shapely union.\"\"\"\n",
    "    ref = faces[idxs[0]]\n",
    "    origin, normal = ref['origin'], ref['normal']\n",
    "    U = project_points(V, origin, normal)  # project all vertices once\n",
    "\n",
    "    polys = []\n",
    "    for k in idxs:\n",
    "        cyc = faces[k]['vertex_ids']\n",
    "        ring = U[np.array(cyc)]\n",
    "        polys.append(Polygon(ring))\n",
    "    merged = unary_union(polys)\n",
    "\n",
    "    out = []\n",
    "    def add_poly(p):\n",
    "        exterior = np.asarray(p.exterior.coords)[:,:2]\n",
    "        holes = [np.asarray(r.coords)[:,:2] for r in p.interiors]\n",
    "        out.append({'origin':origin,'normal':normal,'poly2d':exterior,'holes2d':holes})\n",
    "    if merged.geom_type == 'Polygon':\n",
    "        add_poly(merged)\n",
    "    elif merged.geom_type == 'MultiPolygon':\n",
    "        for p in merged.geoms:\n",
    "            add_poly(p)\n",
    "    return out\n",
    "\n",
    "# ----------------------- Heuristic merge fallback -------------------------- #\n",
    "\n",
    "def merge_group_heuristic(faces: List[Dict], idxs: List[int]):\n",
    "    # Keep largest-area simple boundary per group; drop likely chord-induced cycles\n",
    "    polys = []\n",
    "    for k in idxs:\n",
    "        poly = faces[k]['poly2d']\n",
    "        area = 0.5 * float(np.dot(poly[:,0], np.roll(poly[:,1], -1)) - np.dot(poly[:,1], np.roll(poly[:,0], -1)))\n",
    "        polys.append((k, abs(area)))\n",
    "    polys.sort(key=lambda x: x[1], reverse=True)\n",
    "    # keep top K (could be more than 1 if areas are distinct and non-overlapping)\n",
    "    keep = [polys[0][0]] if polys else []\n",
    "    out = []\n",
    "    for k in keep:\n",
    "        out.append({'origin':faces[k]['origin'],'normal':faces[k]['normal'],'poly2d':faces[k]['poly2d'],'holes2d':[]})\n",
    "    return out\n",
    "\n",
    "# ---------------------------- Build final faces ---------------------------- #\n",
    "\n",
    "def build_merged_faces(V, lines, plane_tol, ang_tol_deg, plane_d_tol, cycle_len_max):\n",
    "    prelim = derive_cycles_as_faces(V, lines, plane_tol, cycle_len_max)\n",
    "    if not prelim:\n",
    "        return []\n",
    "    groups = group_by_plane(prelim, ang_tol_deg, plane_d_tol)\n",
    "    merged = []\n",
    "    for g in groups:\n",
    "        if _HAVE_SHAPELY:\n",
    "            merged.extend(merge_group_shapely(V, prelim, g))\n",
    "        else:\n",
    "            merged.extend(merge_group_heuristic(prelim, g))\n",
    "    return merged\n",
    "\n",
    "# ---------------------------- Point membership ----------------------------- #\n",
    "\n",
    "def point_in_face(p: np.ndarray, face: Dict, maxdist: float) -> bool:\n",
    "    origin, normal = face['origin'], face['normal']\n",
    "    d = float(np.dot(p - origin, normal))\n",
    "    if maxdist > 0 and abs(d) > maxdist:\n",
    "        return False\n",
    "    # 2D projection and winding test with holes\n",
    "    u, v = plane_basis(normal)\n",
    "    k2 = np.array([np.dot(p-origin, u), np.dot(p-origin, v)])\n",
    "    def wn(poly):\n",
    "        x, y = poly[:,0], poly[:,1]\n",
    "        wn = False\n",
    "        for i in range(len(poly)):\n",
    "            j = (i+1) % len(poly)\n",
    "            xi, yi, xj, yj = x[i], y[i], x[j], y[j]\n",
    "            if ((yi > k2[1]) != (yj > k2[1])) and (k2[0] < (xj - xi) * (k2[1] - yi) / ((yj - yi) + 1e-12) + xi):\n",
    "                wn = not wn\n",
    "        return wn\n",
    "    if not wn(face['poly2d']):\n",
    "        return False\n",
    "    for hole in face.get('holes2d', []):\n",
    "        if wn(hole):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# ------------------------------ IO helpers -------------------------------- #\n",
    "\n",
    "def stream_xyz(path: Path, chunk_size: int):\n",
    "    buf = []\n",
    "    with path.open('r', encoding='utf-8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            s = line.strip()\n",
    "            if not s: continue\n",
    "            parts = s.split()\n",
    "            try:\n",
    "                row = [float(x) for x in parts[:3]]\n",
    "            except Exception:\n",
    "                continue\n",
    "            if len(row) < 3: continue\n",
    "            buf.append(row)\n",
    "            if len(buf) >= chunk_size:\n",
    "                yield np.asarray(buf, float); buf.clear()\n",
    "    if buf:\n",
    "        yield np.asarray(buf, float)\n",
    "\n",
    "def write_xyz(out_fh, chunk: np.ndarray, ids: np.ndarray):\n",
    "    for (x,y,z), fid in zip(chunk, ids):\n",
    "        out_fh.write(f\"{x} {y} {z} {int(fid)}\\n\")\n",
    "\n",
    "\n",
    "# ------------------------------ Label runners ----------------------------- #\n",
    "\n",
    "def label_one(xyz_path: Path, obj_path: Path, out_path: Path,\n",
    "              plane_tol: float, ang_tol_deg: float, plane_d_tol: float,\n",
    "              max_distance: float, cycle_len_max: int, chunk_size: int):\n",
    "    V, lines = parse_obj(obj_path)\n",
    "    if len(V) == 0 or len(lines) == 0:\n",
    "        print(f'ERROR: OBJ missing vertices or lines → {obj_path}', file=sys.stderr)\n",
    "        return False\n",
    "    faces = build_merged_faces(V, lines, plane_tol, ang_tol_deg, plane_d_tol, cycle_len_max)\n",
    "    if not faces:\n",
    "        print(f'ERROR: No valid faces derived after merging → {obj_path}', file=sys.stderr)\n",
    "        return False\n",
    "    cents = []\n",
    "    for f in faces:\n",
    "        poly = f['poly2d']\n",
    "        c2 = poly.mean(axis=0)\n",
    "        u, v = plane_basis(f['normal'])\n",
    "        c3 = f['origin'] + c2[0]*u + c2[1]*v\n",
    "        cents.append(c3)\n",
    "    kdt = cKDTree(np.vstack(cents))\n",
    "\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with out_path.open('w') as out_fh:\n",
    "        for chunk in stream_xyz(xyz_path, chunk_size):\n",
    "            ids = np.full(len(chunk), -1, int)\n",
    "            k = min(48, len(faces))\n",
    "            _, cand = kdt.query(chunk, k=k, workers=-1)\n",
    "            if k == 1:\n",
    "                cand = cand.reshape(-1, 1)\n",
    "            for i, p in enumerate(chunk):\n",
    "                best = -1\n",
    "                for fid in cand[i]:\n",
    "                    if point_in_face(p, faces[int(fid)], max_distance):\n",
    "                        best = int(fid); break\n",
    "                ids[i] = best\n",
    "            write_xyz(out_fh, chunk, ids)\n",
    "    return True\n",
    "\n",
    "\n",
    "def label_batch(root: Path, xyz_dir: str = 'xyzs', obj_dir: str = 'objs', out_dir: str = 'outputs',\n",
    "                pattern: str = '*.xyz', **kwargs):\n",
    "    xdir = (root / xyz_dir)\n",
    "    odir = (root / obj_dir)\n",
    "    outd = (out_dir)\n",
    "    if not xdir.exists() or not odir.exists():\n",
    "        print(f'ERROR: Missing input directories: {xdir} or {odir}', file=sys.stderr)\n",
    "        return 2\n",
    "    outd.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    from glob import glob\n",
    "    xyz_files = sorted([Path(p) for p in glob(str(xdir / pattern))])\n",
    "    if not xyz_files:\n",
    "        print(f'No XYZ files found under {xdir} matching {pattern}', file=sys.stderr)\n",
    "        return 3\n",
    "\n",
    "    ok = 0; fail = 0; miss = 0\n",
    "    for xyzp in xyz_files:\n",
    "        stem = xyzp.stem\n",
    "        objp = odir / f'{stem}.obj'\n",
    "        outp = outd / f'{stem}.xyz'\n",
    "        if not objp.exists():\n",
    "            print(f'WARN: OBJ not found for {stem}: {objp}')\n",
    "            miss += 1\n",
    "            continue\n",
    "        print(f'→ Labeling {stem} ...')\n",
    "        res = label_one(xyzp, objp, outp, **kwargs)\n",
    "        if res:\n",
    "            ok += 1\n",
    "        else:\n",
    "            fail += 1\n",
    "    print(f'Done. OK: {ok} | Failed: {fail} | Missing OBJ: {miss} | Outputs → {outd}')\n",
    "    return 0 if fail == 0 else 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ Main Test --------------------------------- #\n",
    "# Manual configuration — replace paths/values as needed\n",
    "xyz_file = Path(\"data/Entry-level/train/xyz/2.xyz\")\n",
    "obj_file = Path(\"data/Entry-level/train/wireframe/2.obj\")\n",
    "out_file = Path(\"outputs/2.xyz\")\n",
    "\n",
    "PLANE_TOL = 0.02\n",
    "ANG_TOL_DEG = 2.0\n",
    "PLANE_D_TOL = 0.05\n",
    "MAX_DISTANCE = 1.0\n",
    "CYCLE_LEN_MAX = 32\n",
    "CHUNK_SIZE = 200000\n",
    "\n",
    "def test_main():\n",
    "    V, lines = parse_obj(obj_file)\n",
    "    if len(V) == 0 or len(lines) == 0:\n",
    "        print('ERROR: OBJ missing vertices or lines.', file=sys.stderr)\n",
    "        return\n",
    "\n",
    "    faces = build_merged_faces(V, lines, PLANE_TOL, ANG_TOL_DEG, PLANE_D_TOL, CYCLE_LEN_MAX)\n",
    "    if not faces:\n",
    "        print('ERROR: No valid faces derived from wireframe after merging.', file=sys.stderr)\n",
    "        return\n",
    "\n",
    "    # KD tree of face centroids for candidate filtering\n",
    "    cents = []\n",
    "    for f in faces:\n",
    "        poly = f['poly2d']\n",
    "        c2 = poly.mean(axis=0)\n",
    "        u, v = plane_basis(f['normal'])\n",
    "        c3 = f['origin'] + c2[0]*u + c2[1]*v\n",
    "        cents.append(c3)\n",
    "    kdt = cKDTree(np.vstack(cents))\n",
    "\n",
    "    with out_file.open('w') as out_fh:\n",
    "        for chunk in stream_xyz(xyz_file, CHUNK_SIZE):\n",
    "            ids = np.full(len(chunk), -1, int)\n",
    "            k = min(48, len(faces))\n",
    "            _, cand = kdt.query(chunk, k=k, workers=-1)\n",
    "            if k == 1:\n",
    "                cand = cand.reshape(-1, 1)\n",
    "            for i, p in enumerate(chunk):\n",
    "                best = -1\n",
    "                for fid in cand[i]:\n",
    "                    if point_in_face(p, faces[int(fid)], MAX_DISTANCE):\n",
    "                        best = int(fid)\n",
    "                        break\n",
    "                ids[i] = best\n",
    "            write_xyz(out_fh, chunk, ids)\n",
    "\n",
    "    if not _HAVE_SHAPELY:\n",
    "        print('NOTE: Shapely not found; used heuristic merge. Install shapely for robust unions.', file=sys.stderr)\n",
    "\n",
    "    print(f\"Derived {len(faces)} merged faces | Wrote: {out_file}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Directory layout for batch mode:\n",
    "/data\n",
    "  ├── xyzs/\n",
    "  │    └── 2.xyz\n",
    "  ├── objs/\n",
    "  │    └── 2.obj\n",
    "  └── outputs/   ← will be created if missing\n",
    "       └── 2.xyz\n",
    "\"\"\"\n",
    "ROOT = Path(\"data/Entry-level/train\")\n",
    "XYZ_DIR = \"xyz\"   # subfolder under each root with .xyz files\n",
    "OBJ_DIR = \"wireframe\"   # subfolder under each root with .obj wireframes\n",
    "OUT_DIR = Path(\"outputs\")  # outputs will be written under each root/OUT_DIR\n",
    "PATTERN = \"*.xyz\"\n",
    "\n",
    "PLANE_TOL = 0.02\n",
    "ANG_TOL_DEG = 2.0\n",
    "PLANE_D_TOL = 0.05\n",
    "MAX_DISTANCE = 1.0\n",
    "CYCLE_LEN_MAX = 32\n",
    "CHUNK_SIZE = 200000\n",
    "\n",
    "def test_main():\n",
    "    kwargs = dict(\n",
    "        plane_tol=PLANE_TOL,\n",
    "        ang_tol_deg=ANG_TOL_DEG,\n",
    "        plane_d_tol=PLANE_D_TOL,\n",
    "        max_distance=MAX_DISTANCE,\n",
    "        cycle_len_max=CYCLE_LEN_MAX,\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "    )\n",
    "    # for root in ROOTS:\n",
    "    root = ROOT\n",
    "    print(f\"→ Labeling batch under: {root}\")\n",
    "    rc = label_batch(root, xyz_dir=XYZ_DIR, obj_dir=OBJ_DIR, out_dir=OUT_DIR, pattern=PATTERN, **kwargs)\n",
    "    if rc != 0:\n",
    "        print(f\"Warning: label_batch returned {rc} for {root}\", file=sys.stderr)\n",
    "    print(\"All done.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sb310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
